{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7f44269-769f-4dec-b410-a1871290d25b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T00:29:35.319394Z",
     "iopub.status.busy": "2024-02-20T00:29:35.318336Z",
     "iopub.status.idle": "2024-02-20T00:29:38.404742Z",
     "shell.execute_reply": "2024-02-20T00:29:38.404426Z",
     "shell.execute_reply.started": "2024-02-20T00:29:35.319344Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "import custom_functions as fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec63ff26-6b6c-46f8-9b21-7cf60b90f6f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T00:29:38.405765Z",
     "iopub.status.busy": "2024-02-20T00:29:38.405611Z",
     "iopub.status.idle": "2024-02-20T00:29:38.430278Z",
     "shell.execute_reply": "2024-02-20T00:29:38.429983Z",
     "shell.execute_reply.started": "2024-02-20T00:29:38.405755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-Level Keys in FPATHS dict:\n",
      "dict_keys(['data', 'images', 'metadata', 'eda', 'models', 'results', 'readme'])\n"
     ]
    }
   ],
   "source": [
    "FPATHS = fn.load_filepaths_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a00d7aa-72f8-4faa-8d4c-c637f9a6117b",
   "metadata": {},
   "source": [
    "## Task: Conversational Retreival Agent "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9804ae15-0000-48ec-afa8-0ee208665169",
   "metadata": {},
   "source": [
    "### Notes:\n",
    "- Reviewing [official example](https://github.com/hwchase17/conversational-retrieval-agent/blob/master/streamlit.py) of RetreivalAgent on blog post.\n",
    "\n",
    "- [ ] Separate retreival tool creation from agent creation.\n",
    "    - [ ] WIll make it easier to swap out data source "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db83af15-3af5-4c6b-901d-503aedc47f0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T00:29:38.431131Z",
     "iopub.status.busy": "2024-02-20T00:29:38.430971Z",
     "iopub.status.idle": "2024-02-20T00:29:38.454905Z",
     "shell.execute_reply": "2024-02-20T00:29:38.454555Z",
     "shell.execute_reply.started": "2024-02-20T00:29:38.431121Z"
    }
   },
   "outputs": [],
   "source": [
    "# import streamlit as st\n",
    "\n",
    "# # @st.cache_data\n",
    "\n",
    "# ## Adding caching to reduce api usage\n",
    "# from langchain.cache import InMemoryCache\n",
    "# # from langchain.document_loaders import CSVLoader\n",
    "# from langchain_community.document_loaders import CSVLoader\n",
    "# from langchain.globals import set_llm_cache\n",
    "# from langchain.memory import ChatMessageHistory, ConversationBufferMemory\n",
    "# from langchain.prompts import (\n",
    "#     ChatPromptTemplate, PromptTemplate,\n",
    "#     HumanMessagePromptTemplate,\n",
    "#     MessagesPlaceholder,\n",
    "#     SystemMessagePromptTemplate,\n",
    "# )\n",
    "# from langchain.text_splitter import CharacterTextSplitter#, SpacyTextSplitter\n",
    "# from langchain_community.vectorstores import FAISS, Chroma\n",
    "# from langchain_openai.chat_models import ChatOpenAI\n",
    "# from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "# # from langchain_community.embeddings.spacy_embeddings import SpacyEmbeddings\n",
    "\n",
    "# # set_llm_cache(InMemoryCache())\n",
    "\n",
    "# from langchain import hub\n",
    "# from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "# from langchain.tools.retriever import create_retriever_tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eafc9daa-d5e7-4736-b42a-524978fefa13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T00:29:38.455635Z",
     "iopub.status.busy": "2024-02-20T00:29:38.455522Z",
     "iopub.status.idle": "2024-02-20T00:29:42.173681Z",
     "shell.execute_reply": "2024-02-20T00:29:42.173105Z",
     "shell.execute_reply.started": "2024-02-20T00:29:38.455625Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (0.0.21)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from langchain-community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from langchain-community) (2.0.24)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from langchain-community) (3.8.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from langchain-community) (0.6.4)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.24 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from langchain-community) (0.1.24)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from langchain-community) (0.1.2)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from langchain-community) (1.23.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from langchain-community) (2.29.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from langchain-community) (8.2.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.20.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1.24->langchain-community) (3.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1.24->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1.24->langchain-community) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1.24->langchain-community) (1.10.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (2024.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.9.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.24->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.24->langchain-community) (2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Top-Level Keys in FPATHS dict:\n",
      "dict_keys(['data', 'images', 'metadata', 'eda', 'models', 'results', 'readme'])\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import custom_functions as fn\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "# from langchain.callbacks import StreamlitCallbackHandler\n",
    "!pip install -U langchain-community\n",
    "from langchain_community.callbacks import StreamlitCallbackHandler\n",
    "\n",
    "from langchain.agents import OpenAIFunctionsAgent, AgentExecutor\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "# Memory: agent token buffer used in original example blog post\n",
    "from langchain.agents.openai_functions_agent.agent_token_buffer_memory import AgentTokenBufferMemory\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "import openai, os\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "FPATHS = fn.load_filepaths_json()\n",
    "fpath_llm_csv = FPATHS['data']['app']['reviews-with-target-for-llm_csv']\n",
    "fpath_db = FPATHS['data']['app']['vector-db_dir']\n",
    "\n",
    "def display_metadata(meta_df,iloc=0, include_details=False):\n",
    "    # product = meta_df.iloc[iloc]\n",
    "    # md = \"#### Product Being Reviewed\"\n",
    "    md = \"\"\n",
    "    md += f'\\n- Product Title:\\n***\\\"{product[\"Title (Raw)\"]}\\\"***'\n",
    "    # md += f\"<p><img src='{product['Product Image']}' width=300px></p>\"\n",
    "    md += f'\\n- Brand: {product[\"Brand\"]}'\n",
    "    md += f\"\\n- Price: {product['Price']}\"\n",
    "    md += f\"\\n- Ranked {product['Rank']} (2018)\"\n",
    "\n",
    "    md += f\"\\n- Categories:\\n    - \"\n",
    "    md += \"; \".join(product['Categories'])\n",
    "    # md += \n",
    "    # md += f\"\\n- Categories:{', '.join(product['Categories'])}\"\n",
    "    \n",
    "    \n",
    "    return md\n",
    "\n",
    "\n",
    "def load_product_info(fpath):\n",
    "    import json\n",
    "    with open(fpath,'r') as f:\n",
    "        product_json = json.load(f)\n",
    "        \n",
    "    product_string = \"Product Info:\\n\"\n",
    "    for k,v in product_json.items():\n",
    "        if k.lower()=='description':\n",
    "            continue\n",
    "        product_string+=f\"\\n{k} = {v}\\n\"\n",
    "        \n",
    "    return product_string\n",
    "\n",
    "# @st.cache_resource\n",
    "def load_vector_database(fpath_db, fpath_csv=None, metadata_columns = ['reviewerID'],\n",
    "                         chunk_size=500, use_previous = True,\n",
    "                         delete=False, as_retriever=False, k=8, **retriever_kwargs):\n",
    "    \n",
    "     # Use EMbedding --> embed chunks --> vectors\n",
    "    embedding_func = OpenAIEmbeddings(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "    \n",
    "    if delete==True:\n",
    "        print(\"Deleting previous Chroma db...\")\n",
    "        # Set use_pervious to False\n",
    "        use_previous= False\n",
    "        db = Chroma(persist_directory=fpath_db, \n",
    "           embedding_function=embedding_func)\n",
    "        db.delete_collection()\n",
    "\n",
    "    if use_previous==True:\n",
    "        print(\"Using previous Chroma db...\")\n",
    "        db =  Chroma(persist_directory=fpath_db, \n",
    "           embedding_function=embedding_func)\n",
    "    else:\n",
    "        print(\"Creating embeddings/Chromadb database\")\n",
    "        if fpath_csv == None:\n",
    "            raise Exception(\"Must pass fpath_csv if use_previous==False or delete==True\")\n",
    "                \n",
    "        # Load Document --> Split into chunks\n",
    "        loader = CSVLoader(fpath_csv,metadata_columns=metadata_columns)\n",
    "        documents = loader.load()\n",
    "        \n",
    "        text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=chunk_size)\n",
    "        docs = text_splitter.split_documents(documents)\n",
    "        \n",
    "        db = Chroma.from_documents(docs, embedding_func, persist_directory= fpath_db)\n",
    "        # Use persist to save to disk\n",
    "        db.persist()\n",
    "\n",
    "    if as_retriever:\n",
    "        return db.as_retriever(k=k, **retriever_kwargs)\n",
    "    else:\n",
    "        return db\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "26b1cd96-a425-49ea-aaf1-fab7eaf8b9d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T02:27:02.545668Z",
     "iopub.status.busy": "2024-02-20T02:27:02.544855Z",
     "iopub.status.idle": "2024-02-20T02:27:06.236417Z",
     "shell.execute_reply": "2024-02-20T02:27:06.235722Z",
     "shell.execute_reply.started": "2024-02-20T02:27:02.545623Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (0.0.21)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.7.4-cp310-cp310-macosx_11_0_arm64.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: langchain-openai in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (0.0.6)\n",
      "Requirement already satisfied: tiktoken in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (0.5.2)\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.6.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from langchain-community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from langchain-community) (2.0.24)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from langchain-community) (3.8.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from langchain-community) (0.6.4)\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.24 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from langchain-community) (0.1.24)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from langchain-community) (0.1.2)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from langchain-community) (1.23.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from langchain-community) (2.29.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from langchain-community) (8.2.3)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from langchain-openai) (1.11.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from tiktoken) (2022.7.9)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.2.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.20.2)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1.24->langchain-community) (3.5.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1.24->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1.24->langchain-community) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1.24->langchain-community) (1.10.14)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (0.26.0)\n",
      "Requirement already satisfied: sniffio in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.2.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.9.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from requests<3,>=2->langchain-community) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (1.0.2)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.24->langchain-community) (2.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Downloading faiss_cpu-1.7.4-cp310-cp310-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.6.0-cp310-cp310-macosx_11_0_arm64.whl (949 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.0/950.0 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu, tiktoken\n",
      "  Attempting uninstall: tiktoken\n",
      "    Found existing installation: tiktoken 0.5.2\n",
      "    Uninstalling tiktoken-0.5.2:\n",
      "      Successfully uninstalled tiktoken-0.5.2\n",
      "Successfully installed faiss-cpu-1.7.4 tiktoken-0.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -U langchain-community faiss-cpu langchain-openai tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0989263f-bccb-4d33-8054-6a6a82b4c28d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T02:27:09.030112Z",
     "iopub.status.busy": "2024-02-20T02:27:09.029077Z",
     "iopub.status.idle": "2024-02-20T02:27:27.447733Z",
     "shell.execute_reply": "2024-02-20T02:27:27.447438Z",
     "shell.execute_reply.started": "2024-02-20T02:27:09.030063Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x2937413c0>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "fpath_csv = FPATHS['data']['app']['reviews-with-target-for-llm_csv']\n",
    "\n",
    "# Use EMbedding --> embed chunks --> vectors\n",
    "embedding_func = OpenAIEmbeddings(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "\n",
    "\n",
    "        \n",
    "# Load Document --> Split into chunks\n",
    "loader = CSVLoader(fpath_csv,metadata_columns = ['reviewerID'])\n",
    "documents = loader.load()\n",
    "\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=500)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "db = FAISS.from_documents(docs, embedding_func)\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a421e5ef-a1d9-44c2-a4b7-1faed53e0d8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T02:27:34.374496Z",
     "iopub.status.busy": "2024-02-20T02:27:34.373411Z",
     "iopub.status.idle": "2024-02-20T02:27:34.432825Z",
     "shell.execute_reply": "2024-02-20T02:27:34.432368Z",
     "shell.execute_reply.started": "2024-02-20T02:27:34.374439Z"
    }
   },
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(k=8)\n",
    "db.save_local()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ff336e65-5d8c-4eb9-9636-9146dc736899",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T02:28:21.410008Z",
     "iopub.status.busy": "2024-02-20T02:28:21.409065Z",
     "iopub.status.idle": "2024-02-20T02:28:21.915690Z",
     "shell.execute_reply": "2024-02-20T02:28:21.915239Z",
     "shell.execute_reply.started": "2024-02-20T02:28:21.409951Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./app-assets/reviews_db'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpath_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cbd86938-4c04-436c-b58f-e823d38de51d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T02:32:52.401957Z",
     "iopub.status.busy": "2024-02-20T02:32:52.401556Z",
     "iopub.status.idle": "2024-02-20T02:32:52.807379Z",
     "shell.execute_reply": "2024-02-20T02:32:52.807042Z",
     "shell.execute_reply.started": "2024-02-20T02:32:52.401933Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(fpath_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "50110793-4753-49b0-a708-6b73235bafa9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T02:28:32.154306Z",
     "iopub.status.busy": "2024-02-20T02:28:32.153896Z",
     "iopub.status.idle": "2024-02-20T02:28:32.225272Z",
     "shell.execute_reply": "2024-02-20T02:28:32.224854Z",
     "shell.execute_reply.started": "2024-02-20T02:28:32.154281Z"
    }
   },
   "outputs": [],
   "source": [
    "db.save_local(fpath_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d265cdff-7a16-41dc-ae63-e9e11d9f41ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T02:29:08.041008Z",
     "iopub.status.busy": "2024-02-20T02:29:08.039977Z",
     "iopub.status.idle": "2024-02-20T02:29:08.248673Z",
     "shell.execute_reply": "2024-02-20T02:29:08.248056Z",
     "shell.execute_reply.started": "2024-02-20T02:29:08.040951Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='review: Two Stars: Cooking process to long and complicated.\\nstars: 2\\ngroup: Low', metadata={'source': 'app-assets/reviews-for-llm.csv', 'row': 3751, 'reviewerID': 'AMSG9YQ8W6LLC'}),\n",
       " Document(page_content=\"review: Love These: If you want to improve the texture, rinse under cold water, blanch for one minute, then dry with a paper towel, then pan fry for ~5 minutes, then cook in your sauce for at least 2 minutes so they absorb the flavor. Also, I've begun to cut these before eating because they're pretty hard to cut once they're on the plate.\\nstars: 5\\ngroup: High\", metadata={'source': 'app-assets/reviews-for-llm.csv', 'row': 4057, 'reviewerID': 'A1TBOU09U1Z3NF'}),\n",
       " Document(page_content='review: Follow the directions!: The trick to these is to prepare them exactly as described in the instructions. Boil for two minutes and then dry in a medium hot pan. That resulted in a a nice texture that was enjoyable to eat.\\nstars: 4\\ngroup:', metadata={'source': 'app-assets/reviews-for-llm.csv', 'row': 2976, 'reviewerID': 'AIV9VBN098BEH'}),\n",
       " Document(page_content='review: Great product: Having read other reviews, I made sure to rinse the \"rice\" for a good 8 minutes. Although preparing it requires more effort than real rice, it takes less time to actually prepare and if you season it correctly, it tastes great!\\nstars: 5\\ngroup: High', metadata={'source': 'app-assets/reviews-for-llm.csv', 'row': 4265, 'reviewerID': 'A14VIW6TDFKPS5'})]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_db = FAISS.load_local(fpath_db, embedding_func)\n",
    "query='Cook time'\n",
    "docs = new_db.similarity_search(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ffe7ca-e219-4ba8-8779-c8af44729a95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4492cc7-f2eb-4eaa-a002-dfe435cead70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T00:29:42.176593Z",
     "iopub.status.busy": "2024-02-20T00:29:42.175962Z",
     "iopub.status.idle": "2024-02-20T00:29:43.167534Z",
     "shell.execute_reply": "2024-02-20T00:29:43.167278Z",
     "shell.execute_reply.started": "2024-02-20T00:29:42.176570Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['agent_scratchpad', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]], 'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')), MessagesPlaceholder(variable_name='chat_history', optional=True), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "prompt_dl = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "prompt_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fb78cfc-1291-4c1a-b4b7-6eaf1a48c1a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T00:29:43.168044Z",
     "iopub.status.busy": "2024-02-20T00:29:43.167947Z",
     "iopub.status.idle": "2024-02-20T00:29:43.197118Z",
     "shell.execute_reply": "2024-02-20T00:29:43.196820Z",
     "shell.execute_reply.started": "2024-02-20T00:29:43.168034Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.prompts.chat.ChatPromptTemplate"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prompt_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8215a37f-54dc-4da2-9746-2b6ff14ba5f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T00:29:43.197778Z",
     "iopub.status.busy": "2024-02-20T00:29:43.197666Z",
     "iopub.status.idle": "2024-02-20T00:29:43.226591Z",
     "shell.execute_reply": "2024-02-20T00:29:43.226290Z",
     "shell.execute_reply.started": "2024-02-20T00:29:43.197769Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
       " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
       " MessagesPlaceholder(variable_name='agent_scratchpad')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_dl.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06db64ef-f338-49cd-be76-29e5fdf87bc4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T00:29:43.227303Z",
     "iopub.status.busy": "2024-02-20T00:29:43.227198Z",
     "iopub.status.idle": "2024-02-20T00:29:43.256610Z",
     "shell.execute_reply": "2024-02-20T00:29:43.256289Z",
     "shell.execute_reply.started": "2024-02-20T00:29:43.227294Z"
    }
   },
   "outputs": [],
   "source": [
    "# k=6\n",
    "# retriever  = fn.load_vector_database( fpath_db,fpath_llm_csv, k=k, use_previous=False, as_retriever=True)#, use_previous=False)\n",
    "# # import custom_functions as fn\n",
    "# from custom_functions.app_functions import load_product_info\n",
    "\n",
    "# product_string = load_product_info(FPATHS['data']['app']['product-metadata-llm_json'])\n",
    "# ## Make retreieval tool\n",
    "# tool = create_retriever_tool(\n",
    "#     retriever,\n",
    "#     \"search_reviews\",\n",
    "#     \"Searches and returns excerpts from Amazon user reviews.\",\n",
    "# )\n",
    "# tools = [tool]\n",
    "\n",
    "#     # Pull starter prompt from langchainhub\n",
    "# # prompt = hub.pull(\"hwchase17/openai-tools-agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef81564a-18ba-48f7-9741-e4d8d75eecf3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T00:29:43.257192Z",
     "iopub.status.busy": "2024-02-20T00:29:43.257102Z",
     "iopub.status.idle": "2024-02-20T00:29:43.286661Z",
     "shell.execute_reply": "2024-02-20T00:29:43.286333Z",
     "shell.execute_reply.started": "2024-02-20T00:29:43.257183Z"
    }
   },
   "outputs": [],
   "source": [
    "# # produt_string = \n",
    "# # # Replace system prompt\n",
    "# template = f\"You are a helpful data analyst for answering questions about what customers said about a specific  Amazon product using only content from use reviews.\"\n",
    "# product_template = f\" Assume all user questions are asking about the content in the user reviews. Note the product metadata is:\\n{product_string}\\n\\n\"\n",
    "# template+=product_template\n",
    "\n",
    "# # template+=\"\\n\\nUse information from the following review documents to answer questions:\"\n",
    "# # qa_prompt_template= \"\\n- Here are the review documents:\\n----------------\\n{agent_scratchpad}\\n\\n\"\n",
    "# qa_prompt_template =\"\"\"Use the following pieces of context (user reviews) to answer the user's question by summarizing the reviews. \n",
    "#         If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n----------------\\n{agent_scratchpad}\\n\\n\"\"\"\n",
    "# template+=qa_prompt_template\n",
    "# # print(template)\n",
    "# system_template= "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a38e75-6d66-48b8-82fd-f545faaf1a4e",
   "metadata": {},
   "source": [
    "```python\n",
    "# downloaded from hub\n",
    "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful assistant')),\n",
    " MessagesPlaceholder(variable_name='chat_history', optional=True),\n",
    " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')),\n",
    " MessagesPlaceholder(variable_name='agent_scratchpad')]\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba89babd-7246-43bb-b41b-c4ba6e9e6a4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T00:29:43.287332Z",
     "iopub.status.busy": "2024-02-20T00:29:43.287230Z",
     "iopub.status.idle": "2024-02-20T00:29:43.315940Z",
     "shell.execute_reply": "2024-02-20T00:29:43.315631Z",
     "shell.execute_reply.started": "2024-02-20T00:29:43.287323Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# prompt_template = OpenAIFunctionsAgent.create_prompt(\n",
    "#     system_message=SystemMessage(template),\n",
    "#     extra_prompt_messages=[MessagesPlaceholder(variable_name=\"history\")],\n",
    "# )\n",
    "# prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71e5f043-2d4a-49a7-b304-c0aa597f966c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T00:29:43.316489Z",
     "iopub.status.busy": "2024-02-20T00:29:43.316390Z",
     "iopub.status.idle": "2024-02-20T00:29:43.344232Z",
     "shell.execute_reply": "2024-02-20T00:29:43.343917Z",
     "shell.execute_reply.started": "2024-02-20T00:29:43.316480Z"
    }
   },
   "outputs": [],
   "source": [
    "# prompt_template.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57f21c48-a413-4fe5-b097-13295b17ff79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T00:29:43.344752Z",
     "iopub.status.busy": "2024-02-20T00:29:43.344661Z",
     "iopub.status.idle": "2024-02-20T00:29:43.372792Z",
     "shell.execute_reply": "2024-02-20T00:29:43.372482Z",
     "shell.execute_reply.started": "2024-02-20T00:29:43.344743Z"
    }
   },
   "outputs": [],
   "source": [
    "# llm = ChatOpenAI(temperature=0,streaming=True)\n",
    "# agent = create_openai_tools_agent(llm, tools, prompt_template)\n",
    "# agent_executor = AgentExecutor(agent=agent, tools=tools,  verbose=True,  #return_intermediate_steps=True,\n",
    "#                                memory=ConversationBufferMemory(memory_key=\"history\",return_messages=True))\n",
    "# agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3ea532c-92cf-49d3-8a9b-42c4eab5d976",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T00:29:43.373367Z",
     "iopub.status.busy": "2024-02-20T00:29:43.373261Z",
     "iopub.status.idle": "2024-02-20T00:29:43.401599Z",
     "shell.execute_reply": "2024-02-20T00:29:43.401036Z",
     "shell.execute_reply.started": "2024-02-20T00:29:43.373358Z"
    }
   },
   "outputs": [],
   "source": [
    "# memory = AgentTokenBufferMemory(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19e0e230-8996-4f1a-aaf4-4fddf58ecaa9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T00:29:43.404654Z",
     "iopub.status.busy": "2024-02-20T00:29:43.404439Z",
     "iopub.status.idle": "2024-02-20T00:29:43.432808Z",
     "shell.execute_reply": "2024-02-20T00:29:43.432478Z",
     "shell.execute_reply.started": "2024-02-20T00:29:43.404641Z"
    }
   },
   "outputs": [],
   "source": [
    "# agent_executor.memory.buffer_as_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9f51dbaf-2540-45a7-a8a7-68ed7e774b43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T00:29:43.433379Z",
     "iopub.status.busy": "2024-02-20T00:29:43.433278Z",
     "iopub.status.idle": "2024-02-20T00:29:43.461809Z",
     "shell.execute_reply": "2024-02-20T00:29:43.461493Z",
     "shell.execute_reply.started": "2024-02-20T00:29:43.433369Z"
    }
   },
   "outputs": [],
   "source": [
    "# starter_message = \"Hello, there! Enter your question here and I will check the full reviews database to provide you the best answer.\"\n",
    "# # session_state_messages = [AIMessage(content=starter_message)]\n",
    "# agent_executor.memory.chat_memory.add_ai_message(starter_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d0a6f9ba-d564-4038-8f8d-1436a3a6a77d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T00:29:43.462492Z",
     "iopub.status.busy": "2024-02-20T00:29:43.462384Z",
     "iopub.status.idle": "2024-02-20T00:29:43.490708Z",
     "shell.execute_reply": "2024-02-20T00:29:43.490401Z",
     "shell.execute_reply.started": "2024-02-20T00:29:43.462482Z"
    }
   },
   "outputs": [],
   "source": [
    "# # session_state_messages.\n",
    "# prompt =\"What is the cooking time?\"\n",
    "\n",
    "# response = agent_executor.invoke(input={'input':prompt})\n",
    "# response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48d36823-a570-4e07-a6e2-2d645c98161e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T00:29:43.491363Z",
     "iopub.status.busy": "2024-02-20T00:29:43.491265Z",
     "iopub.status.idle": "2024-02-20T00:29:43.519915Z",
     "shell.execute_reply": "2024-02-20T00:29:43.519564Z",
     "shell.execute_reply.started": "2024-02-20T00:29:43.491353Z"
    }
   },
   "outputs": [],
   "source": [
    "# response['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3bf8804e-1adb-438f-81eb-bc773edf4114",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T00:29:43.520632Z",
     "iopub.status.busy": "2024-02-20T00:29:43.520476Z",
     "iopub.status.idle": "2024-02-20T00:29:43.549227Z",
     "shell.execute_reply": "2024-02-20T00:29:43.548918Z",
     "shell.execute_reply.started": "2024-02-20T00:29:43.520623Z"
    }
   },
   "outputs": [],
   "source": [
    "# # agent_executor.memory.chat_memory\n",
    "# agent_executor.memory.buffer_as_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ffe8e49-e988-4c49-b82c-994535d6f264",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T00:29:43.549746Z",
     "iopub.status.busy": "2024-02-20T00:29:43.549650Z",
     "iopub.status.idle": "2024-02-20T00:29:43.578824Z",
     "shell.execute_reply": "2024-02-20T00:29:43.578494Z",
     "shell.execute_reply.started": "2024-02-20T00:29:43.549737Z"
    }
   },
   "outputs": [],
   "source": [
    "    \n",
    "## For steramlit try this as raw code, not a function\n",
    "def print_history(agent_executor):\n",
    "    # Simulate streaming for final message\n",
    "\n",
    "    session_state_messages = agent_executor.memory.buffer_as_messages\n",
    "    for msg in session_state_messages:#[:-1]:\n",
    "        if isinstance(msg, AIMessage):\n",
    "            # notebook\n",
    "            print(f\"Assistant: {msg.content}\")\n",
    "            # streamlit\n",
    "            st.chat_message(\"assistant\").write(msg.content)\n",
    "        \n",
    "        elif isinstance(msg, HumanMessage):\n",
    "            # notebook\n",
    "            print(f\"User: {msg.content}\")\n",
    "            # streamlit\n",
    "            st.chat_message(\"user\").write(msg.content)\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d04aae0d-15f1-425c-a87e-439b57be1371",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T00:29:43.579495Z",
     "iopub.status.busy": "2024-02-20T00:29:43.579371Z",
     "iopub.status.idle": "2024-02-20T00:29:43.608219Z",
     "shell.execute_reply": "2024-02-20T00:29:43.607912Z",
     "shell.execute_reply.started": "2024-02-20T00:29:43.579485Z"
    }
   },
   "outputs": [],
   "source": [
    "# print_history(agent_executor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb1e10b9-3b8c-48cc-80bc-e8ce10c4d1e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T00:29:43.608870Z",
     "iopub.status.busy": "2024-02-20T00:29:43.608768Z",
     "iopub.status.idle": "2024-02-20T00:29:43.638696Z",
     "shell.execute_reply": "2024-02-20T00:29:43.638392Z",
     "shell.execute_reply.started": "2024-02-20T00:29:43.608860Z"
    }
   },
   "outputs": [],
   "source": [
    "## Separating the template code to make the rest of the code more modular \n",
    "# Must change/track both the template messages but also the starter message!\n",
    "\n",
    "def get_template_string_reviews():\n",
    "     # Create template with product info\n",
    "    template = f\"You are a helpful data analyst for answering questions about what customers said about a specific  Amazon product using only content from use reviews.\"\n",
    "    from custom_functions.app_functions import load_product_info\n",
    "    product_string = load_product_info(FPATHS['data']['app']['product-metadata-llm_json'])\n",
    "\n",
    "    product_template = f\" Assume all user questions are asking about the content in the user reviews. Note the product metadata is:\\n```{product_string}```\\n\\n\"\n",
    "    template+=product_template\n",
    "    \n",
    "    qa_prompt_template =\"\"\"Use the following pieces of context (user reviews) to answer the user's question by summarizing the reviews. \n",
    "            If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n----------------\\n{agent_scratchpad}\\n\\n\"\"\"\n",
    "    template+=qa_prompt_template\n",
    "    return template\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "652ad937-0cd1-4af9-a567-6aa61dbf899e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T00:29:43.639263Z",
     "iopub.status.busy": "2024-02-20T00:29:43.639165Z",
     "iopub.status.idle": "2024-02-20T00:29:43.667493Z",
     "shell.execute_reply": "2024-02-20T00:29:43.667181Z",
     "shell.execute_reply.started": "2024-02-20T00:29:43.639254Z"
    }
   },
   "outputs": [],
   "source": [
    "# !source ~/.zshrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ca2ed31-be3c-43ed-b546-8014e4278e1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T00:29:43.668096Z",
     "iopub.status.busy": "2024-02-20T00:29:43.668006Z",
     "iopub.status.idle": "2024-02-20T00:29:43.695746Z",
     "shell.execute_reply": "2024-02-20T00:29:43.695434Z",
     "shell.execute_reply.started": "2024-02-20T00:29:43.668088Z"
    }
   },
   "outputs": [],
   "source": [
    "# os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a91bbddb-6c6f-4a43-8c2e-80290b05f90c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T00:29:43.696364Z",
     "iopub.status.busy": "2024-02-20T00:29:43.696264Z",
     "iopub.status.idle": "2024-02-20T00:30:26.604325Z",
     "shell.execute_reply": "2024-02-20T00:30:26.603885Z",
     "shell.execute_reply.started": "2024-02-20T00:29:43.696355Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting previous Chroma db...\n",
      "Creating embeddings/Chromadb database\n"
     ]
    }
   ],
   "source": [
    "## Updated function\n",
    "fpath_llm_csv = FPATHS['data']['app']['reviews-with-target-for-llm_csv']\n",
    "fpath_db = FPATHS['data']['app']['vector-db_dir']\n",
    "\n",
    "# Running one time to delete the database and make fresh\n",
    "retriever  = load_vector_database( fpath_db,fpath_llm_csv, k=8, delete=True)#, use_previous=False)\n",
    "\n",
    "\n",
    "\n",
    "def get_agent(retriever=None,fpath_db=FPATHS['data']['app']['vector-db_dir'], k=8, temperature=0.1, verbose=False,\n",
    "             template_string_func=get_template_string_reviews):\n",
    "    \n",
    "    ## Make retreieval tool\n",
    "    if retriever is None:\n",
    "        retriever  = load_vector_database( fpath_db,fpath_llm_csv, k=k, use_previous=True, as_retriever=True)#, use_previous=False)\n",
    "    tool = create_retriever_tool(\n",
    "        retriever,\n",
    "        \"search_reviews\",\n",
    "        \"Searches and returns excerpts from Amazon user reviews.\",\n",
    "    )\n",
    "    tools = [tool]\n",
    "    \n",
    "    \n",
    "   ## Get template via function for template string\n",
    "    template = template_string_func()\n",
    "\n",
    "\n",
    "    # Create the chatprompttemplate\n",
    "    prompt_template = OpenAIFunctionsAgent.create_prompt(\n",
    "        system_message=SystemMessage(template),\n",
    "        extra_prompt_messages=[MessagesPlaceholder(variable_name=\"history\")],\n",
    "    )\n",
    "    \n",
    "    if verbose:\n",
    "        print(prompt_template.messages)\n",
    "        \n",
    "    llm = ChatOpenAI(temperature=temperature,streaming=True, api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt_template)\n",
    "    agent_executor = AgentExecutor(agent=agent, tools=tools,  verbose=True, #return_intermediate_steps=True,\n",
    "                                   memory=ConversationBufferMemory(memory_key=\"history\",return_messages=True))\n",
    "    return agent_executor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c62d3ba-fa19-4d77-a3a9-1f6fef8544bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T00:30:26.605090Z",
     "iopub.status.busy": "2024-02-20T00:30:26.604956Z",
     "iopub.status.idle": "2024-02-20T00:30:27.131469Z",
     "shell.execute_reply": "2024-02-20T00:30:27.131096Z",
     "shell.execute_reply.started": "2024-02-20T00:30:26.605077Z"
    }
   },
   "outputs": [],
   "source": [
    "# !source ~/.zshrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "991639c9-989f-4888-8fc8-fd3cfc16017e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T00:30:27.132188Z",
     "iopub.status.busy": "2024-02-20T00:30:27.132078Z",
     "iopub.status.idle": "2024-02-20T00:30:27.164787Z",
     "shell.execute_reply": "2024-02-20T00:30:27.164417Z",
     "shell.execute_reply.started": "2024-02-20T00:30:27.132178Z"
    }
   },
   "outputs": [],
   "source": [
    "def reset_agent(#fpath_db = FPATHS['data']['app']['vector-db_dir'],\n",
    "                retriever, \n",
    "                starter_message = \"Hello, there! Enter your question here and I will check the full reviews database to provide you the best answer.\",\n",
    "               get_agent_kws={}):\n",
    "    # fpath_db\n",
    "    agent_exec = get_agent(retriever, **get_agent_kws)\n",
    "    agent_exec.memory.chat_memory.add_ai_message(starter_message)\n",
    "    with chat_container:\n",
    "        st.chat_message(\"assistant\").write_stream(fake_streaming(starter_message))\n",
    "        # print_history(agent_exec)\n",
    "    return agent_exec\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fake_streaming(response):\n",
    "    import time\n",
    "    for word in response.split(\" \"):\n",
    "        yield word + \" \"\n",
    "        time.sleep(.05)\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0839a322-86f8-4ac6-8aa2-71650d672a66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T00:31:24.247812Z",
     "iopub.status.busy": "2024-02-20T00:31:24.246314Z",
     "iopub.status.idle": "2024-02-20T00:31:26.117049Z",
     "shell.execute_reply": "2024-02-20T00:31:26.111507Z",
     "shell.execute_reply.started": "2024-02-20T00:31:24.247658Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using previous Chroma db...\n",
      "Assistant: Hello, there! Enter your question here and I will check the full reviews database to provide you the best answer.\n",
      "\n",
      "CPU times: user 853 ms, sys: 118 ms, total: 971 ms\n",
      "Wall time: 1.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Testing Code\n",
    "agent_exec = get_agent()\n",
    "agent_exec = reset_agent(retriever)\n",
    "print_history(agent_exec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce9a28c-ee26-4458-8680-46f16600e374",
   "metadata": {},
   "source": [
    ">- For more args available as config for agent.invoke:\n",
    ">- https://api.python.langchain.com/en/latest/runnables/langchain_core.runnables.config.RunnableConfig.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ad5354de-b9d6-41c3-9587-076c5de38c9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T00:31:26.256310Z",
     "iopub.status.busy": "2024-02-20T00:31:26.255828Z",
     "iopub.status.idle": "2024-02-20T00:31:28.483192Z",
     "shell.execute_reply": "2024-02-20T00:31:28.478064Z",
     "shell.execute_reply.started": "2024-02-20T00:31:26.256282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search_reviews` with `{'query': 'cook time'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mreview: Love These: If you want to improve the texture, rinse under cold water, blanch for one minute, then dry with a paper towel, then pan fry for ~5 minutes, then cook in your sauce for at least 2 minutes so they absorb the flavor. Also, I've begun to cut these before eating because they're pretty hard to cut once they're on the plate.\n",
      "stars: 5\n",
      "group: High\n",
      "\n",
      "review: Love These: If you want to improve the texture, rinse under cold water, blanch for one minute, then dry with a paper towel, then pan fry for ~5 minutes, then cook in your sauce for at least 2 minutes so they absorb the flavor. Also, I've begun to cut these before eating because they're pretty hard to cut once they're on the plate.\n",
      "stars: 5\n",
      "group: High\n",
      "\n",
      "review: Follow the directions!: The trick to these is to prepare them exactly as described in the instructions. Boil for two minutes and then dry in a medium hot pan. That resulted in a a nice texture that was enjoyable to eat.\n",
      "stars: 4\n",
      "group:\n",
      "\n",
      "review: Follow the directions!: The trick to these is to prepare them exactly as described in the instructions. Boil for two minutes and then dry in a medium hot pan. That resulted in a a nice texture that was enjoyable to eat.\n",
      "stars: 4\n",
      "group:\u001b[0m\u001b[32;1m\u001b[1;3mBased on the reviews, the recommended cook time for the Miracle Noodle Zero Carb, Gluten Free Shirataki Pasta is to boil for two minutes and then dry in a medium hot pan. This results in a nice texture that is enjoyable to eat.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Assistant: Hello, there! Enter your question here and I will check the full reviews database to provide you the best answer.\n",
      "\n",
      "User: What is the cook time?\n",
      "\n",
      "Assistant: Based on the reviews, the recommended cook time for the Miracle Noodle Zero Carb, Gluten Free Shirataki Pasta is to boil for two minutes and then dry in a medium hot pan. This results in a nice texture that is enjoyable to eat.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input = \"What is the cook time?\"\n",
    "response = agent_exec.invoke(input={'input':input})#,  include_run_info=True)\n",
    "# response.keys()\n",
    "print_history(agent_exec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "21837271-5c72-4d2a-abaa-a826df47cf79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T00:31:31.264475Z",
     "iopub.status.busy": "2024-02-20T00:31:31.264035Z",
     "iopub.status.idle": "2024-02-20T00:31:31.324336Z",
     "shell.execute_reply": "2024-02-20T00:31:31.323212Z",
     "shell.execute_reply.started": "2024-02-20T00:31:31.264447Z"
    }
   },
   "outputs": [],
   "source": [
    "# response['__run']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "177f3f23-136e-48e9-bb60-6b0235df0acf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T00:31:31.498530Z",
     "iopub.status.busy": "2024-02-20T00:31:31.498112Z",
     "iopub.status.idle": "2024-02-20T00:31:31.559872Z",
     "shell.execute_reply": "2024-02-20T00:31:31.559501Z",
     "shell.execute_reply.started": "2024-02-20T00:31:31.498505Z"
    }
   },
   "outputs": [],
   "source": [
    "# response['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "df8bcd4b-14d7-422b-891b-c14318b8b957",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T00:31:31.774009Z",
     "iopub.status.busy": "2024-02-20T00:31:31.773410Z",
     "iopub.status.idle": "2024-02-20T00:31:33.735709Z",
     "shell.execute_reply": "2024-02-20T00:31:33.734697Z",
     "shell.execute_reply.started": "2024-02-20T00:31:31.773972Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search_reviews` with `{'query': 'flavor'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mreview: Four Stars: nice flavor\n",
      "stars: 4\n",
      "group:\n",
      "\n",
      "review: Four Stars: nice flavor\n",
      "stars: 4\n",
      "group:\n",
      "\n",
      "review: Five Stars: Great flavor\n",
      "stars: 5\n",
      "group: High\n",
      "\n",
      "review: Five Stars: Great flavor\n",
      "stars: 5\n",
      "group: High\u001b[0m\u001b[32;1m\u001b[1;3mCustomers have mentioned that the flavor of the Miracle Noodle Zero Carb, Gluten Free Shirataki Pasta is nice and great, as indicated by the reviews with ratings of four and five stars.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Assistant: Hello, there! Enter your question here and I will check the full reviews database to provide you the best answer.\n",
      "\n",
      "User: What is the cook time?\n",
      "\n",
      "Assistant: Based on the reviews, the recommended cook time for the Miracle Noodle Zero Carb, Gluten Free Shirataki Pasta is to boil for two minutes and then dry in a medium hot pan. This results in a nice texture that is enjoyable to eat.\n",
      "\n",
      "User: What is the flavor like?\n",
      "\n",
      "Assistant: Customers have mentioned that the flavor of the Miracle Noodle Zero Carb, Gluten Free Shirataki Pasta is nice and great, as indicated by the reviews with ratings of four and five stars.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input = \"What is the flavor like?\"\n",
    "response = agent_exec.invoke(input={'input':input})#, include_run_info=True)\n",
    "print_history(agent_exec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03aa19e-20c3-4dd0-bdd5-4270a6a30f47",
   "metadata": {},
   "source": [
    "```python\n",
    "## Streamlit if statement for getting/displaying response\n",
    "\n",
    "user_text = st.chat_input(placeholder=\"Enter your question here.\")\n",
    "\n",
    "if user_text:\n",
    "    with chat_container:\n",
    "        \n",
    "        print_history(st.session_state['agent'])\n",
    "        st.chat_message(\"user\").write(user_text)\n",
    "        \n",
    "        response = st.session_state['agent'].invoke({\"input\":user_text})\n",
    "        st.chat_message('assistant').write(fake_streaming(response['output']))\n",
    "\n",
    "reset_chat = st.sidebar.button(\"Reset Chat?\")\n",
    "if reset_chat:\n",
    "    st.session_state['agent'] =reset_agent(retriever)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dfb8bc-3537-48f1-b631-468751b60c44",
   "metadata": {},
   "source": [
    "### Entire Functional App Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40914c6-8aa1-445a-b5c7-96f50bedfc98",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-02-20T00:31:19.211392Z",
     "iopub.status.idle": "2024-02-20T00:31:19.211596Z",
     "shell.execute_reply": "2024-02-20T00:31:19.211492Z",
     "shell.execute_reply.started": "2024-02-20T00:31:19.211485Z"
    }
   },
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import custom_functions as fn\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.callbacks import StreamlitCallbackHandler\n",
    "from langchain.callbacks import StdOutCallbackHandler\n",
    "from langchain.agents import OpenAIFunctionsAgent, AgentExecutor\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.schema import SystemMessage, HumanMessage, AIMessage\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "# Memory: agent token buffer used in original example blog post\n",
    "from langchain.agents.openai_functions_agent.agent_token_buffer_memory import AgentTokenBufferMemory\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "#https://github.com/langchain-ai/streamlit-agent/blob/main/streamlit_agent/chat_with_documents.py\n",
    "from langchain.memory.chat_message_histories.streamlit import StreamlitChatMessageHistory\n",
    "\n",
    "import openai, os\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "FPATHS = fn.load_filepaths_json()\n",
    "fpath_llm_csv = FPATHS['data']['app']['reviews-with-target-for-llm_csv']\n",
    "fpath_db = FPATHS['data']['app']['vector-db_dir']\n",
    "\n",
    "\n",
    "@st.cache_resource\n",
    "def load_vector_database(fpath_db, fpath_csv=None, metadata_columns = ['reviewerID'],\n",
    "                         chunk_size=500, use_previous = True,\n",
    "                         delete=False, as_retriever=False, k=8, **retriever_kwargs):\n",
    "    \n",
    "     # Use EMbedding --> embed chunks --> vectors\n",
    "    embedding_func = OpenAIEmbeddings(api_key=os.getenv('OPENAI_API_KEY'))\n",
    "    \n",
    "    if delete==True:\n",
    "        print(\"Deleting previous Chroma db...\")\n",
    "        # Set use_pervious to False\n",
    "        use_previous= False\n",
    "        db = Chroma(persist_directory=fpath_db, \n",
    "           embedding_function=embedding_func)\n",
    "        db.delete_collection()\n",
    "\n",
    "    if use_previous==True:\n",
    "        print(\"Using previous Chroma db...\")\n",
    "        db =  Chroma(persist_directory=fpath_db, \n",
    "           embedding_function=embedding_func)\n",
    "    else:\n",
    "        print(\"Creating embeddings/Chromadb database\")\n",
    "        if fpath_csv == None:\n",
    "            raise Exception(\"Must pass fpath_csv if use_previous==False or delete==True\")\n",
    "                \n",
    "        # Load Document --> Split into chunks\n",
    "        loader = CSVLoader(fpath_csv,metadata_columns=metadata_columns)\n",
    "        documents = loader.load()\n",
    "        \n",
    "        text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=chunk_size)\n",
    "        docs = text_splitter.split_documents(documents)\n",
    "        \n",
    "        db = Chroma.from_documents(docs, embedding_func, persist_directory= fpath_db)\n",
    "        # Use persist to save to disk\n",
    "        db.persist()\n",
    "\n",
    "    if as_retriever:\n",
    "        return db.as_retriever(k=k, **retriever_kwargs)\n",
    "    else:\n",
    "        return db\n",
    "\n",
    "## Updated function\n",
    "fpath_llm_csv = FPATHS['data']['app']['reviews-with-target-for-llm_csv']\n",
    "fpath_db = FPATHS['data']['app']['vector-db_dir']\n",
    "\n",
    "with st.spinner(\"Constructing vector database for ChatGPT...\"):\n",
    "    # Running one time to delete the database and make fresh\n",
    "    retriever  = load_vector_database( fpath_db,fpath_llm_csv, k=8, delete=True, as_retriever=True)\n",
    "\n",
    "# Create chat container early\n",
    "chat_container = st.container()\n",
    "\n",
    "def get_template_string_reviews():\n",
    "     # Create template with product info\n",
    "    template = f\"You are a helpful data analyst for answering questions about what customers said about a specific  Amazon product using only content from use reviews.\"\n",
    "    from custom_functions.app_functions import load_product_info\n",
    "    product_string = load_product_info(FPATHS['data']['app']['product-metadata-llm_json'])\n",
    "\n",
    "    product_template = f\" Assume all user questions are asking about the content in the user reviews. Note the product metadata is:\\n```{product_string}```\\n\\n\"\n",
    "    template+=product_template\n",
    "    \n",
    "    qa_prompt_template =\"\"\"Use the following pieces of context (user reviews) to answer the user's question by summarizing the reviews. \n",
    "            If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n----------------\\n{agent_scratchpad}\\n\\n\"\"\"\n",
    "    template+=qa_prompt_template\n",
    "    return template\n",
    "    \n",
    "    \n",
    "\n",
    "def get_agent(retriever=None,fpath_db=FPATHS['data']['app']['vector-db_dir'], k=8, temperature=0.1, verbose=False,\n",
    "             template_string_func=get_template_string_reviews):\n",
    "    \n",
    "    ## Make retreieval tool\n",
    "    if retriever is None:\n",
    "        retriever  = load_vector_database( fpath_db,fpath_llm_csv, k=k, use_previous=True, as_retriever=True)#, use_previous=False)\n",
    "    tool = create_retriever_tool(\n",
    "        retriever,\n",
    "        \"search_reviews\",\n",
    "        \"Searches and returns excerpts from Amazon user reviews.\",\n",
    "    )\n",
    "    tools = [tool]\n",
    "    \n",
    "    \n",
    "   ## Get template via function for template string\n",
    "    template = template_string_func()\n",
    "\n",
    "    # Create the chatprompttemplate\n",
    "    prompt_template = OpenAIFunctionsAgent.create_prompt(\n",
    "        system_message=SystemMessage(template),\n",
    "        extra_prompt_messages=[MessagesPlaceholder(variable_name=\"history\")],\n",
    "    )\n",
    "    \n",
    "    if verbose:\n",
    "        print(prompt_template.messages)\n",
    "        \n",
    "    llm = ChatOpenAI(temperature=temperature,streaming=True, api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt_template)\n",
    "    \n",
    "    ## Creating streamlit-friendly memory for streaming\n",
    "    agent_executor = AgentExecutor(agent=agent, tools=tools,  verbose=True, #return_intermediate_steps=True,\n",
    "                                   memory=ConversationBufferMemory(memory_key=\"history\",return_messages=True))\n",
    "    return agent_executor\n",
    "\n",
    "\n",
    "        \n",
    "            \n",
    "            \n",
    "def reset_agent(#fpath_db = FPATHS['data']['app']['vector-db_dir'],\n",
    "                retriever, \n",
    "                starter_message = \"Hello, there! Enter your question here and I will check the full reviews database to provide you the best answer.\",\n",
    "               get_agent_kws={}):\n",
    "    # fpath_db\n",
    "    agent_exec = get_agent(retriever, **get_agent_kws)\n",
    "    agent_exec.memory.chat_memory.add_ai_message(starter_message)\n",
    "    with chat_container:\n",
    "        st.chat_message(\"assistant\").write_stream(fake_streaming(starter_message))\n",
    "        # print_history(agent_exec)\n",
    "    return agent_exec\n",
    "    \n",
    "\n",
    "def fake_streaming(response):\n",
    "    import time\n",
    "    for word in response.split(\" \"):\n",
    "        yield word + \" \"\n",
    "        time.sleep(.05)\t\t\n",
    "        \n",
    "            \n",
    "    \n",
    "## For steramlit try this as raw code, not a function\n",
    "def print_history(agent_executor):\n",
    "    # Simulate streaming for final message\n",
    "\n",
    "    session_state_messages = agent_executor.memory.buffer_as_messages\n",
    "    for msg in session_state_messages:#[:-1]:\n",
    "        if isinstance(msg, AIMessage):\n",
    "            # notebook\n",
    "            print(f\"Assistant: {msg.content}\")\n",
    "            # streamlit\n",
    "            st.chat_message(\"assistant\").write(msg.content)\n",
    "        \n",
    "        elif isinstance(msg, HumanMessage):\n",
    "            # notebook\n",
    "            print(f\"User: {msg.content}\")\n",
    "            # streamlit\n",
    "            st.chat_message(\"user\").write(msg.content)\n",
    "        print()\n",
    "\n",
    "\n",
    "if 'agent' not in st.session_state:\n",
    "    # agent = get_agent(retriever)\n",
    "    st.session_state['agent'] =reset_agent(retriever)\n",
    "        \n",
    "\n",
    "user_text = st.chat_input(placeholder=\"Enter your question here.\")\n",
    "\n",
    "if user_text:\n",
    "    with chat_container:\n",
    "        \n",
    "        print_history(st.session_state['agent'])\n",
    "        st.chat_message(\"user\").write(user_text)\n",
    "        \n",
    "        response = st.session_state['agent'].invoke({\"input\":user_text})\n",
    "        st.chat_message('assistant').write(fake_streaming(response['output']))\n",
    "\n",
    "reset_chat = st.sidebar.button(\"Reset Chat?\")\n",
    "if reset_chat:\n",
    "    st.session_state['agent'] =reset_agent(retriever)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2918243-0dde-4cf6-ae26-5392e6efaae1",
   "metadata": {},
   "source": [
    "# Task: Interpret Ngrams/Summaries\n",
    "- Based on current app page 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a8d3d4d8-ecd6-426c-9122-a7f37d9f02df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T00:32:46.363923Z",
     "iopub.status.busy": "2024-02-20T00:32:46.363249Z",
     "iopub.status.idle": "2024-02-20T00:32:46.418929Z",
     "shell.execute_reply": "2024-02-20T00:32:46.418545Z",
     "shell.execute_reply.started": "2024-02-20T00:32:46.363890Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def display_metadata(meta_df,iloc=0, include_details=False):\n",
    "    # product = meta_df.iloc[iloc]\n",
    "    # md = \"#### Product Being Reviewed\"\n",
    "    md = \"\"\n",
    "    md += f'\\n- Product Title:\\n***\\\"{product[\"Title (Raw)\"]}\\\"***'\n",
    "    # md += f\"<p><img src='{product['Product Image']}' width=300px></p>\"\n",
    "    md += f'\\n- Brand: {product[\"Brand\"]}'\n",
    "    md += f\"\\n- Price: {product['Price']}\"\n",
    "    md += f\"\\n- Ranked {product['Rank']} (2018)\"\n",
    "\n",
    "    md += f\"\\n- Categories:\\n    - \"\n",
    "    md += \"; \".join(product['Categories'])\n",
    "    # md += \n",
    "    # md += f\"\\n- Categories:{', '.join(product['Categories'])}\"\n",
    "    \n",
    "    \n",
    "    return md\n",
    "\n",
    "\n",
    "def load_product_info(fpath):\n",
    "    import json\n",
    "    with open(fpath,'r') as f:\n",
    "        product_json = json.load(f)\n",
    "        \n",
    "    product_string = \"Product Info:\\n\"\n",
    "    for k,v in product_json.items():\n",
    "        if k.lower()=='description':\n",
    "            continue\n",
    "        product_string+=f\"\\n{k} = {v}\\n\"\n",
    "        \n",
    "    return product_string\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ae3c31a5-46e4-4734-b135-70011c7e8444",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T00:32:42.768531Z",
     "iopub.status.busy": "2024-02-20T00:32:42.767477Z",
     "iopub.status.idle": "2024-02-20T00:32:43.193487Z",
     "shell.execute_reply": "2024-02-20T00:32:43.192831Z",
     "shell.execute_reply.started": "2024-02-20T00:32:42.768473Z"
    }
   },
   "outputs": [],
   "source": [
    "# @st.cache_data    \n",
    "def load_df(fpath):\n",
    "    import joblib\n",
    "    return joblib.load(fpath)\n",
    "\n",
    "# @st.cache_data\n",
    "def load_metadata(fpath):\n",
    "    import pandas as pd\n",
    "    return pd.read_json(fpath)\n",
    "\n",
    "\n",
    "\n",
    "# @st.cache_data\n",
    "def load_summaries(fpath):\n",
    "    import json\n",
    "    with open(fpath) as f:\n",
    "        summaries = json.load(f)\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "00b4a78f-0151-49ee-92c3-f5277166a298",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T00:31:18.811702Z",
     "iopub.status.busy": "2024-02-20T00:31:18.811614Z",
     "iopub.status.idle": "2024-02-20T00:31:18.841222Z",
     "shell.execute_reply": "2024-02-20T00:31:18.840868Z",
     "shell.execute_reply.started": "2024-02-20T00:31:18.811693Z"
    }
   },
   "outputs": [],
   "source": [
    "## Trying json loader for summaries\n",
    "# def get_summary_json_loader(fpath)\n",
    "# from langchain_community.document_loaders import JSONLoader\n",
    "\n",
    "\n",
    "# loader = JSONLoader(\n",
    "#     file_path=FPATHS['results']['review-summary-01_json'], content_key='summaries',\n",
    "#     jq_schema = \n",
    "#     # jq_schema='.messages[]',\n",
    "#     # content_key=\"content\",\n",
    "#     # metadata_func=metadata_func\n",
    "#     text_content=True\n",
    "# )\n",
    "\n",
    "# data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "96fd4e34-b9e5-4a01-bd16-4f142c9f3a6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T00:32:50.562516Z",
     "iopub.status.busy": "2024-02-20T00:32:50.561752Z",
     "iopub.status.idle": "2024-02-20T00:32:50.696581Z",
     "shell.execute_reply": "2024-02-20T00:32:50.696215Z",
     "shell.execute_reply.started": "2024-02-20T00:32:50.562479Z"
    }
   },
   "outputs": [],
   "source": [
    "df = load_df(FPATHS['data']['processed-nlp']['processed-reviews-with-target_joblib'])\n",
    "meta_df = load_metadata(FPATHS['data']['app']['product-metadata_json'])\n",
    "product= meta_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b50f9f81-748e-4ce5-bc7e-abcbb1af5462",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T00:45:53.062439Z",
     "iopub.status.busy": "2024-02-20T00:45:53.061784Z",
     "iopub.status.idle": "2024-02-20T00:45:53.112351Z",
     "shell.execute_reply": "2024-02-20T00:45:53.111947Z",
     "shell.execute_reply.started": "2024-02-20T00:45:53.062390Z"
    }
   },
   "outputs": [],
   "source": [
    "## Load in new form of summaries\n",
    "summaries = load_summaries(FPATHS['results']['review-summary-01_json'])\n",
    "summary_low = summaries['summary-low']\n",
    "summary_high = summaries['summary-high']\n",
    "# st.subheader(\"Low Reviews\")\n",
    "# st.markdown(\">\"+summaries['summary-low'])\n",
    "# st.subheader(\"High Reviews\")\n",
    "# st.markdown(\">\" + summaries['summary-high'])\n",
    "# st.divider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8634234e-871b-47a4-9de7-c7d6b14688b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:16:26.767804Z",
     "iopub.status.busy": "2024-02-20T01:16:26.766772Z",
     "iopub.status.idle": "2024-02-20T01:16:26.851209Z",
     "shell.execute_reply": "2024-02-20T01:16:26.850779Z",
     "shell.execute_reply.started": "2024-02-20T01:16:26.767767Z"
    }
   },
   "outputs": [],
   "source": [
    "# from langchain.chains import LLMChain\n",
    "\n",
    "# prompt_template = \"Tell me a {adjective} joke\"\n",
    "# prompt = PromptTemplate(\n",
    "#     input_variables=[\"adjective\"], template=prompt_template\n",
    "# )\n",
    "# llm = LLMChain(llm=OpenAI(), prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "197f17be-ff47-4ba6-b5d5-cd061da60965",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:19:54.965704Z",
     "iopub.status.busy": "2024-02-20T01:19:54.965290Z",
     "iopub.status.idle": "2024-02-20T01:19:55.030180Z",
     "shell.execute_reply": "2024-02-20T01:19:55.029769Z",
     "shell.execute_reply.started": "2024-02-20T01:19:54.965678Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Def get_template_string_interpret()\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "def get_task_options(options_only=False):\n",
    "    task_prompt_dict= {\"Summary of Customer Sentiment\":'provide a summary list of what 1-star reviews (group=Low) did not like,  and a summary of what did 5-star (group=High) reviews liked.',\n",
    "                   'Product Recommendations':'provide a list of 3-5 actionable business recommendations on how to improve the product.',\n",
    "                   'Marketing Recommendations':'provide a list of 3-5 recommendations for the marketing team to on how to better set customer expectations before purchasing the product or to better target the customers who will enjoy it.'}\n",
    "    if options_only:\n",
    "        return list(task_prompt_dict.keys())\n",
    "    else:\n",
    "        return task_prompt_dict\n",
    "\n",
    "\n",
    "\n",
    "def get_template_string_interpret(context_low, context_high, context_type='summary'):\n",
    "    # task_prompt_dict = get_task_options(options_only=False)\n",
    "    # system_prompt = task_prompt_dict[selected_task]\n",
    "    \n",
    "    template_assistant = \"You are a helpful assistant data scientist who uses NLP analysis of customer reviews to inform business-decision-making. Answer all questions using the following context:\"\n",
    "    context = f\"\\nGroup Contexts:\\n Here is a {context_type} of 1-star reviews: ```{context_low}```.\\n\\n Here is a {context_type} of 5-star reviews:```{context_high}.\"\n",
    "    template_assistant+=context\n",
    "    return template_assistant\n",
    "\n",
    "\n",
    "\n",
    "agent_summaries = get_agent(retriever,\n",
    "    template_string_func=lambda: get_template_string_interpret(context_low=summary_low, context_high=summary_high)\n",
    ")\n",
    "agent_summaries.input_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "72c2361e-a072-45e6-90b6-a83e5223b492",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:22:27.200211Z",
     "iopub.status.busy": "2024-02-20T01:22:27.199203Z",
     "iopub.status.idle": "2024-02-20T01:22:27.248588Z",
     "shell.execute_reply": "2024-02-20T01:22:27.248135Z",
     "shell.execute_reply.started": "2024-02-20T01:22:27.200166Z"
    }
   },
   "outputs": [],
   "source": [
    "# agent_summaries.agent.prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "877ec03e-34d0-4696-8fe9-65b3829f7a1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:20:11.418175Z",
     "iopub.status.busy": "2024-02-20T01:20:11.417172Z",
     "iopub.status.idle": "2024-02-20T01:20:11.468994Z",
     "shell.execute_reply": "2024-02-20T01:20:11.468496Z",
     "shell.execute_reply.started": "2024-02-20T01:20:11.418117Z"
    }
   },
   "outputs": [],
   "source": [
    "# agent_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d45c2a2b-d974-45cb-93d5-600649878479",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:03:10.036358Z",
     "iopub.status.busy": "2024-02-20T01:03:10.035272Z",
     "iopub.status.idle": "2024-02-20T01:03:10.090306Z",
     "shell.execute_reply": "2024-02-20T01:03:10.089722Z",
     "shell.execute_reply.started": "2024-02-20T01:03:10.036295Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_summaries.memory.buffer_as_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c13b38c6-0eef-4242-8afb-feb3fe2dd4d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:21:09.216883Z",
     "iopub.status.busy": "2024-02-20T01:21:09.216446Z",
     "iopub.status.idle": "2024-02-20T01:21:09.311935Z",
     "shell.execute_reply": "2024-02-20T01:21:09.311438Z",
     "shell.execute_reply.started": "2024-02-20T01:21:09.216853Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Summary of Customer Sentiment'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## CHANGE CODE TO ADD HUMAN/AI MESSAGE to empty history\n",
    "# Specify task options\n",
    "task_options = get_task_options(options_only=True) #task_prompt_dict.keys()\n",
    "task_dict  =get_task_options(options_only=False)\n",
    "selected_task = st.radio(\"Select task:\", options=task_options, index=0)\n",
    "selected_task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "54f9c770-bbc7-4078-ac87-361b42c58d4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:21:15.334338Z",
     "iopub.status.busy": "2024-02-20T01:21:15.333934Z",
     "iopub.status.idle": "2024-02-20T01:21:15.731752Z",
     "shell.execute_reply": "2024-02-20T01:21:15.731415Z",
     "shell.execute_reply.started": "2024-02-20T01:21:15.334313Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'provide a summary list of what 1-star reviews (group=Low) did not like,  and a summary of what did 5-star (group=High) reviews liked.'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_text =  task_dict[selected_task]\n",
    "prompt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "881f9943-2acd-4019-9042-1a4143ca73fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:22:45.736988Z",
     "iopub.status.busy": "2024-02-20T01:22:45.735946Z",
     "iopub.status.idle": "2024-02-20T01:22:50.459359Z",
     "shell.execute_reply": "2024-02-20T01:22:50.458036Z",
     "shell.execute_reply.started": "2024-02-20T01:22:45.736929Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search_reviews` with `{'query': '1-star reviews'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mreview: One Star: not good\n",
      "stars: 1\n",
      "group: Low\n",
      "\n",
      "review: One Star: not good\n",
      "stars: 1\n",
      "group: Low\n",
      "\n",
      "review: One Star: No good\n",
      "stars: 1\n",
      "group: Low\n",
      "\n",
      "review: One Star: No good\n",
      "stars: 1\n",
      "group: Low\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `search_reviews` with `{'query': '5-star reviews'}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mreview: Five Stars: Great experience\n",
      "stars: 5\n",
      "group: High\n",
      "\n",
      "review: Five Stars: Great experience\n",
      "stars: 5\n",
      "group: High\n",
      "\n",
      "review: Five Stars: Great\n",
      "stars: 5\n",
      "group: High\n",
      "\n",
      "review: Five Stars: Great\n",
      "stars: 5\n",
      "group: High\u001b[0m\u001b[32;1m\u001b[1;3m### Summary of 1-Star Reviews (Low):\n",
      "- The Shirataki noodles are rubbery in texture and don't absorb the cooking sauce.\n",
      "- They are impossible to cook.\n",
      "- They have a bad smell.\n",
      "- They taste bad.\n",
      "- They make a mess and are difficult to prepare.\n",
      "- The reviewer wants to return them and get a refund.\n",
      "- The reviewer prefers spagetti squash and brown rice over these noodles.\n",
      "\n",
      "### Summary of 5-Star Reviews (High):\n",
      "- Miracle Noodle Fettuccini is a low carb, healthy pasta alternative for people watching carbs.\n",
      "- The noodles smell a little when first opened but improve after boiling.\n",
      "- The texture is good and they taste good.\n",
      "- They work well in various dishes like chicken teriyaki and homemade pasta sauce with ground turkey.\n",
      "- They are fat-free and low or no calories, making them great for calorie-conscious individuals.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "### Summary of 1-Star Reviews (Low):\n",
      "- The Shirataki noodles are rubbery in texture and don't absorb the cooking sauce.\n",
      "- They are impossible to cook.\n",
      "- They have a bad smell.\n",
      "- They taste bad.\n",
      "- They make a mess and are difficult to prepare.\n",
      "- The reviewer wants to return them and get a refund.\n",
      "- The reviewer prefers spagetti squash and brown rice over these noodles.\n",
      "\n",
      "### Summary of 5-Star Reviews (High):\n",
      "- Miracle Noodle Fettuccini is a low carb, healthy pasta alternative for people watching carbs.\n",
      "- The noodles smell a little when first opened but improve after boiling.\n",
      "- The texture is good and they taste good.\n",
      "- They work well in various dishes like chicken teriyaki and homemade pasta sauce with ground turkey.\n",
      "- They are fat-free and low or no calories, making them great for calorie-conscious individuals.\n"
     ]
    }
   ],
   "source": [
    "response = agent_summaries.invoke({'input':prompt_text})\n",
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1ffff015-9d89-4111-bc3f-99547aa3c516",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-20T01:23:13.024177Z",
     "iopub.status.busy": "2024-02-20T01:23:13.023775Z",
     "iopub.status.idle": "2024-02-20T01:23:13.075216Z",
     "shell.execute_reply": "2024-02-20T01:23:13.074804Z",
     "shell.execute_reply.started": "2024-02-20T01:23:13.024152Z"
    }
   },
   "outputs": [],
   "source": [
    "# def get_response_from_task(selected_task):\n",
    "#     prompt_text = task_options[selected_task]\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c397af63-357c-47e8-9a73-d52b5ba6f635",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Task: introducing myself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a910fda2-a0cc-4434-b756-797060936a7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T20:45:27.071155Z",
     "iopub.status.busy": "2024-02-16T20:45:27.071057Z",
     "iopub.status.idle": "2024-02-16T20:45:27.096038Z",
     "shell.execute_reply": "2024-02-16T20:45:27.095704Z",
     "shell.execute_reply.started": "2024-02-16T20:45:27.071146Z"
    }
   },
   "outputs": [],
   "source": [
    "############# Q&A with ChatGPT\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.memory import ChatMessageHistory, ConversationSummaryBufferMemory, ConversationBufferMemory\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.schema import HumanMessage, AIMessage, SystemMessage\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, SystemMessagePromptTemplate, AIMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "51862c8b-c823-44d3-98cf-5112d15b5e86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T20:45:27.096727Z",
     "iopub.status.busy": "2024-02-16T20:45:27.096629Z",
     "iopub.status.idle": "2024-02-16T20:45:29.865894Z",
     "shell.execute_reply": "2024-02-16T20:45:29.865198Z",
     "shell.execute_reply.started": "2024-02-16T20:45:27.096719Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in /opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages (3.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "af42a579-c97d-49e5-a7b8-983b4d948f6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T20:45:29.868308Z",
     "iopub.status.busy": "2024-02-16T20:45:29.868096Z",
     "iopub.status.idle": "2024-02-16T20:45:29.904328Z",
     "shell.execute_reply": "2024-02-16T20:45:29.903991Z",
     "shell.execute_reply.started": "2024-02-16T20:45:29.868286Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PyPDF2._reader.PdfReader at 0x290d3cc10>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "fpath_resume = \"app-assets/James Irving Resume 2024.pdf\"\n",
    "data = PdfReader(fpath_resume)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c9ec758c-d764-41a6-838d-969af1a3e0cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T20:45:29.905074Z",
     "iopub.status.busy": "2024-02-16T20:45:29.904886Z",
     "iopub.status.idle": "2024-02-16T20:45:29.930154Z",
     "shell.execute_reply": "2024-02-16T20:45:29.929808Z",
     "shell.execute_reply.started": "2024-02-16T20:45:29.905062Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4e059558-4357-4791-95e6-0e55b5667e02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T20:45:29.930806Z",
     "iopub.status.busy": "2024-02-16T20:45:29.930706Z",
     "iopub.status.idle": "2024-02-16T20:45:29.953200Z",
     "shell.execute_reply": "2024-02-16T20:45:29.952844Z",
     "shell.execute_reply.started": "2024-02-16T20:45:29.930797Z"
    }
   },
   "outputs": [],
   "source": [
    "pages = data.pages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6c75f488-09fd-4287-99e5-94d716959578",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T20:45:29.953762Z",
     "iopub.status.busy": "2024-02-16T20:45:29.953666Z",
     "iopub.status.idle": "2024-02-16T20:45:29.976676Z",
     "shell.execute_reply": "2024-02-16T20:45:29.976349Z",
     "shell.execute_reply.started": "2024-02-16T20:45:29.953754Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'/Type': '/Page', '/Parent': IndirectObject(2, 0, 11019734032), '/Resources': IndirectObject(4, 0, 11019734032), '/Contents': IndirectObject(3, 0, 11019734032), '/MediaBox': [0, 0, 612, 792], '/Annots': IndirectObject(10, 0, 11019734032)}\n"
     ]
    }
   ],
   "source": [
    "page = data.pages[0]\n",
    "print(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d71d3e0b-d8bc-49b6-a122-3df1ba2f1635",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T20:45:29.977392Z",
     "iopub.status.busy": "2024-02-16T20:45:29.977283Z",
     "iopub.status.idle": "2024-02-16T20:45:30.001661Z",
     "shell.execute_reply": "2024-02-16T20:45:30.001331Z",
     "shell.execute_reply.started": "2024-02-16T20:45:29.977382Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['addTransformation',\n",
       " 'add_transformation',\n",
       " 'annotations',\n",
       " 'artBox',\n",
       " 'artbox',\n",
       " 'bleedBox',\n",
       " 'bleedbox',\n",
       " 'clear',\n",
       " 'clone',\n",
       " 'compressContentStreams',\n",
       " 'compress_content_streams',\n",
       " 'copy',\n",
       " 'createBlankPage',\n",
       " 'create_blank_page',\n",
       " 'cropBox',\n",
       " 'cropbox',\n",
       " 'extractText',\n",
       " 'extract_text',\n",
       " 'extract_xform_text',\n",
       " 'fromkeys',\n",
       " 'get',\n",
       " 'getContents',\n",
       " 'getObject',\n",
       " 'getXmpMetadata',\n",
       " 'get_contents',\n",
       " 'get_object',\n",
       " 'hash_func',\n",
       " 'hash_value',\n",
       " 'hash_value_data',\n",
       " 'images',\n",
       " 'indirect_ref',\n",
       " 'indirect_reference',\n",
       " 'items',\n",
       " 'keys',\n",
       " 'mediaBox',\n",
       " 'mediabox',\n",
       " 'mergePage',\n",
       " 'mergeRotatedPage',\n",
       " 'mergeRotatedScaledPage',\n",
       " 'mergeRotatedScaledTranslatedPage',\n",
       " 'mergeRotatedTranslatedPage',\n",
       " 'mergeScaledPage',\n",
       " 'mergeScaledTranslatedPage',\n",
       " 'mergeTransformedPage',\n",
       " 'mergeTranslatedPage',\n",
       " 'merge_page',\n",
       " 'pdf',\n",
       " 'pop',\n",
       " 'popitem',\n",
       " 'raw_get',\n",
       " 'readFromStream',\n",
       " 'read_from_stream',\n",
       " 'rotate',\n",
       " 'rotateClockwise',\n",
       " 'rotateCounterClockwise',\n",
       " 'rotate_clockwise',\n",
       " 'rotation',\n",
       " 'scale',\n",
       " 'scaleBy',\n",
       " 'scaleTo',\n",
       " 'scale_by',\n",
       " 'scale_to',\n",
       " 'setdefault',\n",
       " 'transfer_rotation_to_content',\n",
       " 'trimBox',\n",
       " 'trimbox',\n",
       " 'update',\n",
       " 'user_unit',\n",
       " 'values',\n",
       " 'writeToStream',\n",
       " 'write_to_stream',\n",
       " 'xmpMetadata',\n",
       " 'xmp_metadata']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in dir(page) if not i.startswith(\"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ab693b0e-17bd-49ce-a3cc-ab76c90bb145",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T20:45:32.737313Z",
     "iopub.status.busy": "2024-02-16T20:45:32.735868Z",
     "iopub.status.idle": "2024-02-16T20:45:32.780932Z",
     "shell.execute_reply": "2024-02-16T20:45:32.780488Z",
     "shell.execute_reply.started": "2024-02-16T20:45:32.737270Z"
    }
   },
   "outputs": [],
   "source": [
    "# data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9ab03e75-6af2-490d-ba1e-faf2ac269a4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T20:45:32.945014Z",
     "iopub.status.busy": "2024-02-16T20:45:32.943984Z",
     "iopub.status.idle": "2024-02-16T20:45:32.990748Z",
     "shell.execute_reply": "2024-02-16T20:45:32.990234Z",
     "shell.execute_reply.started": "2024-02-16T20:45:32.944955Z"
    }
   },
   "outputs": [],
   "source": [
    "# first_page = pages[0]\n",
    "# for i,page in enumerate(pages):\n",
    "#     if i==0:\n",
    "#         continue\n",
    "#     else:\n",
    "#         first_page.merge_page(page)\n",
    "        \n",
    "# first_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b1e4421c-adc5-4767-b953-8fe21b0f6446",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T20:45:33.295196Z",
     "iopub.status.busy": "2024-02-16T20:45:33.294475Z",
     "iopub.status.idle": "2024-02-16T20:45:33.347014Z",
     "shell.execute_reply": "2024-02-16T20:45:33.346472Z",
     "shell.execute_reply.started": "2024-02-16T20:45:33.295160Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(first_page.extract_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "488258eb-1695-46cc-b910-86826efaf4ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T20:45:33.569274Z",
     "iopub.status.busy": "2024-02-16T20:45:33.568465Z",
     "iopub.status.idle": "2024-02-16T20:45:33.835745Z",
     "shell.execute_reply": "2024-02-16T20:45:33.835451Z",
     "shell.execute_reply.started": "2024-02-16T20:45:33.569225Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAMES M. IRVING, PH.D. 8222 Spadderdock Way, Laurel, MD, 20724 | (518) 322-6750 | james.irving.phd@gmail.com |  LINKEDIN: james-irving-phd | GITHHUB; https://github.com/jirvingphd  SUMMARY Versatile neuroscience-turned-data scientist with expertise in neuroscience research and a strong foundation in experimental design and cognitive neuroscience. Proven ability to apply advanced data science techniques, including statistical modeling, machine learning, and data visualization, to extract valuable insights from complex datasets. Proficient in Python programming and proven ability to rapidly master new technologies and programming languages, which facilitates effective interdisciplinary collaboration and promotes robust, data-driven decision-making processes. Possesses a keen analytical mindset and problem-solving skills honed through successful transitions between disciplines. Demonstrates commitment to continuous learning and innovation, aiming to address scientific challenges and contribute to transformative advancements in both neuroscience and data science. SKILLS • Data Analysis • Statistical Modeling • Machine Learning • Data Visualization • Experimental Design • Quantitative Research Methods • Time Series Analysis • Signal Processing • Cognitive Neuroscience • Behavioral Analysis • Database Management • Pattern Recognition • Python Programming • Deep Learning • Natural Language Processing • AI/LLM Model Implementation • Adaptive Communication Style • Problem Solving & Critical Thinking EXPERIENCE Curriculum Writer - Data Science  Coding Dojo | Remote | Mar 2023-Jan 2024 • Authored and delivered three advanced data science courses covering Time Series Modeling, NLP, and Model Deployment to facilitate skill acquisition for over 100 learners. • Enhanced and extended the curriculum of a 16-week boot camp to a 24-week program, resulting in a 50% increase in instructional depth and engagement. • Developed and implemented Monday.com boards, including public forms and executive-facing Gantt charts, to automate internal workflows and streamline curriculum management, resolving over 100 issues. • Integrated APIs, Web scraping, and Computer Vision (CNNs) into course content, fostering practical skill development and aligning with industry demands in data science and machine learning. Data Science Instructor | Remote November 2021 - March 2023 • Achieved outstanding Net Promoter Scores (NPS) exceeding 90% through the delivery of engaging live lectures, demonstrating effective communication and pedagogical skills. • Implemented automated tools for administrative tasks, reducing student onboarding time from 5 hours to a mere 2 minutes, optimizing operational efficiency. • Authored and delivered a highly acclaimed 4-week course with a perfect NPS rating, showcasing expertise in curriculum development and instructional delivery. • Designed and presented over 16 interactive live lectures and code-along projects, significantly enhancing student participation and fostering a dynamic learning environment. Data Science Instructor  Flatiron School | Remote | Oct 2019-Oct 2021 • Mentored and supervised 60+ students to successfully transition into data science, achieving a high post-program employment rate. • Led and conducted 90-minute study groups weekly, accumulating over 270 hours of recorded lessons, enhancing student comprehension and engagement. • Spearheaded the development and implementation of the \"Flex\" boot camp program, refining instructional design and delivery methods to meet diverse learning needs. \n",
      "------------------------------------\n",
      "• Established three student-progress-tracking Looker dashboards, providing real-time insights into student performance and facilitating timely intervention strategies. • Implemented data-driven approaches to enhance program efficacy, resulting in improved student outcomes and program satisfaction. Laboratory Manager  University of Maryland, School of Medicine | Baltimore, MD | Jul 2017-Aug 2018 • Ensured full compliance with regulatory standards as the lab's public representative, achieving a flawless record with all 4 inspections passing without demerits. • Negotiated and finalized a technical hardware contract worth approximately $100,000 with vendors, optimizing procurement processes and ensuring cost-effectiveness. • Managed and administered over 20 TBs of both cloud and local data storage systems, ensuring data accessibility, security, and efficient retrieval. • Successfully overhauled mouse colony management procedures, resulting in a remarkable 60% reduction in housing costs, from approximately $3.8k/month to $1.5k/month, through strategic resource allocation and process optimization. Postdoctoral Research Fellow | Baltimore, MD June 2015 - July 2017 • Spearheaded neuroscience research endeavors, employing cutting-edge techniques such as in vivo optogenetics and electrophysiology recordings, resulting in groundbreaking insights into neural functioning in awake and behaving mice. • Developed approximately 30 custom analysis scripts in languages including Matlab, NexScript, MedPC, and Arduino, enhancing data processing capabilities and facilitating comprehensive statistical analyses of large datasets. • Mentored and guided a diverse team comprising 1 postdoc, 2 Ph.D. students, 3 lab techs, and 3 undergraduate volunteers, fostering an environment of collaborative learning and achieving research excellence. • Demonstrated self-directed learning by mastering Matlab programming and independently creating custom-designed analysis programs for large datasets in multiple programming languages, streamlining data interpretation processes and enhancing research efficiency. DATA SCIENCE PROJECTS Amazon Reviews NLP Analysis - GitHub Link Natural Language Processing Analysis, Modeling, and Deployment with Actionable Insights • Designed and deployed a user-centric Streamlit dashboard, integrating live sentiment predictions and interactive analysis of trends to guide strategic decision-making. • Conducted sentiment analysis on over 5 million Amazon Grocery & Gourmet Food reviews, utilizing NLP and machine learning techniques (Logistic Regression, Tf-idf vectorization) to identify key factors affecting customer satisfaction and achieve 95%  accuracy in sentiment classification. • Employed Hugging Face transformers and langchain/ChatGPT within the dashboard for summarization and insights, translating vast consumer feedback into actionable product enhancement strategies. How to Make a Successful Movie – GitHub Link Constructing and analyzing an extensive movie database with machine-learning-based insights + Tableau Dashboard • Engineered a comprehensive MySQL database integrating IMDB and data from TMDB API for data-driven insights. • Designed an interactive Tableau dashboard to communicate findings to stakeholders, enhancing decision-making processes (see GitHub link). • Applied A/B Testing to make informed recommendations on what movies are successful at the box office. How to Spot a Troll – GitHub Link Classifying Russian Troll Tweets vs Authentic Tweets • Conducted EDA on 3M tweets, identifying patterns indicative of non-authentic activity by Russian Troll Farms. • Produced alternative final models - one optimized for speed, one for accuracy. Recidivism Risk Assessment – GitHub Link Classifying which released prisoners in Iowa will return to a life of crime using Next-Gen Gradient Boosted Trees • Built a classification model to predict recidivism risk among released prisoners with over 70% accuracy (via scikit-learn and Catboost). • Researched Iowa's state sentencing guidelines and sentencing enhancements to engineer new numerical features to capture the severity of the crimes committed and the duration of sentences. \n",
      "------------------------------------\n",
      "EDUCATION Data Science (Full-Time)         February 2019 - August 2019 Flatiron School Doctor of Philosophy               August 2009 - May 2015 Neuroscience University of Maryland, Baltimore, MD Bachelor & Master of Science       August 2004 - December 2008         Neuroscience Tulane University, New Orleans, LA PROFESSIONAL SKILLS Programming: • Python & Object-Oriented Programming • SQL (MySQL, SQLAlchemy) • MATLAB • PyPi Package Publishing • HTML / CSS • NexScript programming • MedState Notation • Git/GitHub Data Analysis • Extract, Transform, Load (ETL)  (numpy, pandas), • AB Testing (scipy, statsmodels, GraphPad Prism, SPSS) • Machine Learning (scikit-learn, Keras, Catboost, XGBoost), • Database Administration Software: • Adobe Illustrator • Adobe Photoshop • GraphPad Prism • Microsoft Office (Word, Excel, PowerPoint) • NeuroExplorer • Plexon OfflineSorter • VS Code • Jupyter Notebook/Lab Visualization/Dashboarding • Plotly / Dash • Tableau • Streamlit Deployment • Seaborn / Matplotlib • Looker Natural Language Processing: • nltk  • spaCy • Tensorflow • Hugging Face transformers • LangChain \n",
      " \n"
     ]
    }
   ],
   "source": [
    "page_texts = []\n",
    "for page in data.pages:\n",
    "    page_texts.append(page.extract_text())\n",
    "resume_text = \"\\n------------------------------------\\n\".join(page_texts)\n",
    "print(resume_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "de9256db-2d5e-4449-8f30-878e53ce0c34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T20:48:21.524649Z",
     "iopub.status.busy": "2024-02-16T20:48:21.523598Z",
     "iopub.status.idle": "2024-02-16T20:48:21.588418Z",
     "shell.execute_reply": "2024-02-16T20:48:21.588028Z",
     "shell.execute_reply.started": "2024-02-16T20:48:21.524592Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tiktoken\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo-0125\")#\"gpt-3.5-turbo-instruct\")\n",
    "len(encoding.encode(\"tiktoken is great!\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0c41b8-936d-4c93-9799-28a1d877e215",
   "metadata": {},
   "source": [
    "for  gpt-3.5.turbo-0125, context window is 16,385, returns up to 4096 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "64c8362c-01c1-45e2-8ae9-66888e1967a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T20:53:27.170045Z",
     "iopub.status.busy": "2024-02-16T20:53:27.169652Z",
     "iopub.status.idle": "2024-02-16T20:53:27.216401Z",
     "shell.execute_reply": "2024-02-16T20:53:27.216022Z",
     "shell.execute_reply.started": "2024-02-16T20:53:27.170020Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1657"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoding.encode(resume_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1147851d-c3ee-4804-bfd8-287e19aa8b83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b136cdc1-12e8-4927-b3aa-799463cc9a4e",
   "metadata": {},
   "source": [
    "https://towardsdatascience.com/langchain-question-answering-agent-over-docs-18e5585bdbd3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "eecdaf86-ae0c-4913-ab25-201223db5b47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T20:55:17.673602Z",
     "iopub.status.busy": "2024-02-16T20:55:17.673204Z",
     "iopub.status.idle": "2024-02-16T20:55:17.716976Z",
     "shell.execute_reply": "2024-02-16T20:55:17.716586Z",
     "shell.execute_reply.started": "2024-02-16T20:55:17.673578Z"
    }
   },
   "outputs": [],
   "source": [
    "# text_splitter = CharacterTextSplitter(chunk_size=1000, separator=\"\\n\", chunk_overlap=100)\n",
    "# texts = text_splitter.split_text(resume_text)\n",
    "# len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a781023e-82bf-4730-81eb-c0856f34885a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T21:14:31.367761Z",
     "iopub.status.busy": "2024-02-16T21:14:31.367369Z",
     "iopub.status.idle": "2024-02-16T21:14:31.424506Z",
     "shell.execute_reply": "2024-02-16T21:14:31.424165Z",
     "shell.execute_reply.started": "2024-02-16T21:14:31.367736Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['context']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "sys_template = \"You are digital AI clone of the person in the attached resume context. Note: you should not make up anything that you do not know about the person. Here is the context:\\n------\\n{context}\\n\\n------\\n\\n Now introcuce yourself.\"\n",
    "sys_message_prompt= SystemMessagePromptTemplate.from_template(sys_template)#, input_variables=['context']),\n",
    "sys_message_prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d81f49-c805-4181-94e1-327a50bae75b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5c805b63-a745-4473-84e9-a41c405f3f23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T21:14:31.727054Z",
     "iopub.status.busy": "2024-02-16T21:14:31.726657Z",
     "iopub.status.idle": "2024-02-16T21:14:31.774501Z",
     "shell.execute_reply": "2024-02-16T21:14:31.774101Z",
     "shell.execute_reply.started": "2024-02-16T21:14:31.727025Z"
    }
   },
   "outputs": [],
   "source": [
    "# # ai_template =  \"Hello, there!\\nIts a pleasure to meet you. My name is {persons_name} and I am a {occupation}. Would you like to learn some more about me?\"\n",
    "# # ai_message_prompt = AIMessagePromptTemplate.from_template(ai_template)# input_variables=['persons_name','occupation'])\n",
    "# # ai_message_prompt \n",
    "\n",
    "# human_template = \"{question}\"\n",
    "# human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "# human_message_prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4537a449-5d07-44c7-8cf0-12e9dd8b855e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T21:14:31.931500Z",
     "iopub.status.busy": "2024-02-16T21:14:31.931108Z",
     "iopub.status.idle": "2024-02-16T21:14:31.975927Z",
     "shell.execute_reply": "2024-02-16T21:14:31.975607Z",
     "shell.execute_reply.started": "2024-02-16T21:14:31.931476Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], template='You are digital AI clone of the person in the attached resume context. Note: you should not make up anything that you do not know about the person. Here is the context:\\n------\\n{context}\\n\\n------\\n\\n Now introcuce yourself.'))])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages([sys_message_prompt])#, human_message_prompt])\n",
    "chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "962b6d28-2cb4-4c38-ac04-c951583cf801",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T21:14:34.699851Z",
     "iopub.status.busy": "2024-02-16T21:14:34.699462Z",
     "iopub.status.idle": "2024-02-16T21:14:34.744498Z",
     "shell.execute_reply": "2024-02-16T21:14:34.744015Z",
     "shell.execute_reply.started": "2024-02-16T21:14:34.699827Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['context']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "dd321e0e-f6c3-46bc-84e3-a1cf1f8cb214",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T21:14:34.967339Z",
     "iopub.status.busy": "2024-02-16T21:14:34.966951Z",
     "iopub.status.idle": "2024-02-16T21:14:35.014214Z",
     "shell.execute_reply": "2024-02-16T21:14:35.013887Z",
     "shell.execute_reply.started": "2024-02-16T21:14:34.967315Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "request = chat_prompt.format_prompt(context=resume_text).to_messages()\n",
    "len(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "98a984c3-0ff4-4791-869a-0a6a16dbfc10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T21:14:35.705994Z",
     "iopub.status.busy": "2024-02-16T21:14:35.705526Z",
     "iopub.status.idle": "2024-02-16T21:14:38.284165Z",
     "shell.execute_reply": "2024-02-16T21:14:38.283229Z",
     "shell.execute_reply.started": "2024-02-16T21:14:35.705969Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am a versatile neuroscience-turned-data scientist with a strong background in neuroscience research and expertise in experimental design and cognitive neuroscience. I have a proven track record of applying advanced data science techniques such as statistical modeling, machine learning, and data visualization to extract valuable insights from complex datasets. Proficient in Python programming, I have the ability to quickly adapt to new technologies and programming languages, enabling effective interdisciplinary collaboration and data-driven decision-making processes. My analytical mindset, problem-solving skills, and commitment to continuous learning have allowed me to successfully navigate transitions between disciplines and contribute to transformative advancements in both neuroscience and data science.\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(temperature=.5, model=\"gpt-3.5-turbo-0125\")\n",
    "response = llm.invoke(request)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a5f36513-1b90-44af-979b-d58afc114c9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T21:14:38.293240Z",
     "iopub.status.busy": "2024-02-16T21:14:38.292855Z",
     "iopub.status.idle": "2024-02-16T21:14:38.318984Z",
     "shell.execute_reply": "2024-02-16T21:14:38.318660Z",
     "shell.execute_reply.started": "2024-02-16T21:14:38.293216Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I am a versatile neuroscience-turned-data scientist with a strong background in neuroscience research and expertise in experimental design and cognitive neuroscience. I have a proven track record of applying advanced data science techniques such as statistical modeling, machine learning, and data visualization to extract valuable insights from complex datasets. Proficient in Python programming, I have the ability to quickly adapt to new technologies and programming languages, enabling effective interdisciplinary collaboration and data-driven decision-making processes. My analytical mindset, problem-solving skills, and commitment to continuous learning have allowed me to successfully navigate transitions between disciplines and contribute to transformative advancements in both neuroscience and data science.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff26950-c278-4fbd-97ea-fedc547868ec",
   "metadata": {},
   "source": [
    "### Using Sequential Chain to summarize resume first.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "45d25633-5c17-4298-b597-446035c3abc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T21:20:30.044885Z",
     "iopub.status.busy": "2024-02-16T21:20:30.044406Z",
     "iopub.status.idle": "2024-02-16T21:20:30.094222Z",
     "shell.execute_reply": "2024-02-16T21:20:30.093870Z",
     "shell.execute_reply.started": "2024-02-16T21:20:30.044860Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain, LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "9bf74819-63c3-41df-ac4a-5114d4d0856b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T21:27:20.533525Z",
     "iopub.status.busy": "2024-02-16T21:27:20.532471Z",
     "iopub.status.idle": "2024-02-16T21:27:20.579698Z",
     "shell.execute_reply": "2024-02-16T21:27:20.579148Z",
     "shell.execute_reply.started": "2024-02-16T21:27:20.533465Z"
    }
   },
   "outputs": [],
   "source": [
    "template1 = \"Give a summary of this person's resume as a personal history/narrative:\\n{resume}\"\n",
    "prompt1 = ChatPromptTemplate.from_template(template1)\n",
    "chain_1 = LLMChain(llm=llm,\n",
    "                     prompt=prompt1,\n",
    "                     output_key=\"personal_history\")\n",
    "\n",
    "\n",
    "# template2 = \"\"\n",
    "template2 = \"You are a clone of James Irving from the attached resume. Please introduce yourself to a potential new employer but do not quote the resume. Note: you should not make up anything that you do not know about the person. Here is the context\\n--------\\n{personal_history}:\"\n",
    "prompt2 = ChatPromptTemplate.from_template(template2)\n",
    "chain_2 = LLMChain(llm=llm,\n",
    "                     prompt=prompt2,\n",
    "                     output_key=\"introduction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c64cdb31-5f08-4864-965c-d6b037135c07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T21:27:21.333225Z",
     "iopub.status.busy": "2024-02-16T21:27:21.331904Z",
     "iopub.status.idle": "2024-02-16T21:27:21.379819Z",
     "shell.execute_reply": "2024-02-16T21:27:21.379403Z",
     "shell.execute_reply.started": "2024-02-16T21:27:21.333184Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialChain(verbose=True, chains=[LLMChain(prompt=ChatPromptTemplate(input_variables=['resume'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['resume'], template=\"Give a summary of this person's resume as a personal history/narrative:\\n{resume}\"))]), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x2960525c0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x296053a60>, model_name='gpt-3.5-turbo-0125', temperature=0.5, openai_api_key='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', openai_proxy=''), output_key='personal_history'), LLMChain(prompt=ChatPromptTemplate(input_variables=['personal_history'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['personal_history'], template='You are a clone of James Irving from the attached resume. Please introduce yourself to a potential new employer but do not quote the resume. Note: you should not make up anything that you do not know about the person. Here is the context\\n--------\\n{personal_history}:'))]), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x2960525c0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x296053a60>, model_name='gpt-3.5-turbo-0125', temperature=0.5, openai_api_key='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', openai_proxy=''), output_key='introduction')], input_variables=['resume'], output_variables=['personal_history', 'introduction'])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intro_chain = SequentialChain(chains=[chain_1,chain_2], input_variables=['resume'],\n",
    "                             output_variables=['personal_history','introduction'],\n",
    "                             verbose=True)\n",
    "intro_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "04a21db8-0c01-4048-88fb-6f99e0bbeec1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T21:27:21.881663Z",
     "iopub.status.busy": "2024-02-16T21:27:21.880639Z",
     "iopub.status.idle": "2024-02-16T21:27:30.291339Z",
     "shell.execute_reply": "2024-02-16T21:27:30.290189Z",
     "shell.execute_reply.started": "2024-02-16T21:27:21.881603Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=intro_chain.invoke(resume_text)\n",
    "type(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "91e1a3db-a99e-49de-a089-d6e945095e4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T21:27:30.295710Z",
     "iopub.status.busy": "2024-02-16T21:27:30.295064Z",
     "iopub.status.idle": "2024-02-16T21:27:30.332513Z",
     "shell.execute_reply": "2024-02-16T21:27:30.331981Z",
     "shell.execute_reply.started": "2024-02-16T21:27:30.295673Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['resume', 'personal_history', 'introduction'])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a88cd64f-9180-4509-bb0a-a86554c14e61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T21:27:30.333493Z",
     "iopub.status.busy": "2024-02-16T21:27:30.333240Z",
     "iopub.status.idle": "2024-02-16T21:27:30.362018Z",
     "shell.execute_reply": "2024-02-16T21:27:30.361537Z",
     "shell.execute_reply.started": "2024-02-16T21:27:30.333475Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, my name is James Irving. I am a neuroscience-turned-data scientist with a strong background in experimental design and cognitive neuroscience. I have experience applying advanced data science techniques such as statistical modeling, machine learning, and data visualization to extract valuable insights from complex datasets. I am proficient in Python programming and have a track record of quickly mastering new technologies and programming languages to facilitate effective interdisciplinary collaboration.\n",
      "\n",
      "In my previous roles, I have authored and delivered advanced data science courses, achieved outstanding Net Promoter Scores, and mentored students to successfully transition into data science. I have also managed data storage systems, optimized procedures, and spearheaded neuroscience research endeavors while mentoring a diverse team.\n",
      "\n",
      "I hold a Doctor of Philosophy in Neuroscience and have completed a Data Science program, along with a Bachelor and Master of Science in Neuroscience. My professional skills include programming, data analysis, software, visualization/dashboarding, and natural language processing. I have worked on various data science projects, demonstrating my expertise in applying data science techniques to real-world problems. I am committed to continuous learning and innovation to address scientific challenges and contribute to transformative advancements in both neuroscience and data science.\n"
     ]
    }
   ],
   "source": [
    "print(results['introduction'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37501ae4-544b-4a7e-bbc6-9c07d05cc248",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T21:26:02.438541Z",
     "iopub.status.busy": "2024-02-16T21:26:02.437503Z",
     "iopub.status.idle": "2024-02-16T21:26:02.483927Z",
     "shell.execute_reply": "2024-02-16T21:26:02.483500Z",
     "shell.execute_reply.started": "2024-02-16T21:26:02.438479Z"
    }
   },
   "source": [
    "#### Now start a new converastion with this introduction ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "cd342ec7-d16d-4c2a-8311-8c23de75dbfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T21:25:29.990489Z",
     "iopub.status.busy": "2024-02-16T21:25:29.989431Z",
     "iopub.status.idle": "2024-02-16T21:25:30.039864Z",
     "shell.execute_reply": "2024-02-16T21:25:30.039366Z",
     "shell.execute_reply.started": "2024-02-16T21:25:29.990431Z"
    }
   },
   "outputs": [],
   "source": [
    "# AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3174117-cac1-4976-9a00-70ddf7f901ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc5c1713-aef0-4e0e-8196-6feb7f16e8af",
   "metadata": {},
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "375777dc-91d9-4329-a7bc-77257b3ab108",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T21:39:06.390479Z",
     "iopub.status.busy": "2024-02-16T21:39:06.388616Z",
     "iopub.status.idle": "2024-02-16T21:39:06.474552Z",
     "shell.execute_reply": "2024-02-16T21:39:06.474168Z",
     "shell.execute_reply.started": "2024-02-16T21:39:06.390418Z"
    }
   },
   "outputs": [],
   "source": [
    "# from langchain.agents import load_tools\n",
    "# # from langchain.agents.initialize impor in\n",
    "# from langchain.agents import AgentType\n",
    "# from langchain_openai.llms import OpenAI\n",
    "\n",
    "# dir(AgentType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "b595e5d6-09df-4ec4-8dad-eb8f2edff880",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T21:39:07.941896Z",
     "iopub.status.busy": "2024-02-16T21:39:07.941147Z",
     "iopub.status.idle": "2024-02-16T21:39:07.992623Z",
     "shell.execute_reply": "2024-02-16T21:39:07.992161Z",
     "shell.execute_reply.started": "2024-02-16T21:39:07.941846Z"
    }
   },
   "outputs": [],
   "source": [
    "# tools = load_tools([\"llm-math\"], llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "6e969c51-396e-4abb-a924-3d1e588e9240",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T21:39:08.974116Z",
     "iopub.status.busy": "2024-02-16T21:39:08.973558Z",
     "iopub.status.idle": "2024-02-16T21:39:09.022871Z",
     "shell.execute_reply": "2024-02-16T21:39:09.022442Z",
     "shell.execute_reply.started": "2024-02-16T21:39:08.974063Z"
    }
   },
   "outputs": [],
   "source": [
    "# agent = initialize_agent(tools, \n",
    "#                          llm, \n",
    "#                          agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, \n",
    "#                          verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "dc63a0bc-697e-4b70-b675-c352414c7002",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-16T21:39:10.873712Z",
     "iopub.status.busy": "2024-02-16T21:39:10.873312Z",
     "iopub.status.idle": "2024-02-16T21:39:10.927222Z",
     "shell.execute_reply": "2024-02-16T21:39:10.926639Z",
     "shell.execute_reply.started": "2024-02-16T21:39:10.873687Z"
    }
   },
   "outputs": [],
   "source": [
    "# agent = create_react_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d784f0-898c-43d0-b45d-f841ba758657",
   "metadata": {},
   "source": [
    "# From QA App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3053e4fb-094e-4d1d-8a82-d6536b4d6a5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9aad6d-a98b-457a-a666-c7a683171537",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fpath_llm_csv = FPATHS['data']['app']['reviews-with-target-for-llm_csv']\n",
    "# fpath_db = FPATHS['data']['app']['vector-db_dir']\n",
    "\n",
    "# db = fn.load_vector_database( fpath_db,fpath_llm_csv, delete=True)#, use_previous=False)\n",
    "\n",
    "def get_agent(fpath_db, k=8, temperature=0.1,\n",
    "             return_messages=True, verbose=False):\n",
    "    \n",
    "    \n",
    "    # import custom_functions as fn\n",
    "    from custom_functions.app_functions import load_product_info\n",
    "    product_string = load_product_info(FPATHS['data']['app']['product-metadata-llm_json'])\n",
    "    ## Make retreieval tool\n",
    "    tool = create_retriever_tool(\n",
    "         db.as_retriever(k=k),\n",
    "        \"search_reviews\",\n",
    "        \"Searches and returns excerpts from Amazon user reviews.\",\n",
    "    )\n",
    "    tools = [tool]\n",
    "\n",
    "    # Pull starter prompt from langchainhub\n",
    "    prompt = hub.pull(\"hwchase17/openai-tools-agent\")\n",
    "\n",
    "    # produt_string = \n",
    "    # # Replace system prompt\n",
    "    template = f\"You are a helpful data analyst for answering questions about what customers said about a specific  Amazon product using only content from use reviews.\"\n",
    "    product_template = f\" Assume all user questions are asking about the content in the user reviews. Note the product metadata is:\\n```{product_string}```\\n\\n\"\n",
    "    template+=product_template\n",
    "    \n",
    "    # template+=\"\\n\\nUse information from the following review documents to answer questions:\"\n",
    "    # qa_prompt_template= \"\\n- Here are the review documents:\\n----------------\\n{agent_scratchpad}\\n\\n\"\n",
    "    qa_prompt_template =\"\"\"Use the following pieces of context (user reviews) to answer the user's question by summarizing the reviews. \n",
    "            If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n----------------\\n{agent_scratchpad}\\n\\n\"\"\"\n",
    "    template+=qa_prompt_template\n",
    "    # template+=\"Try to infer one based on the review documents, otherwise just say that you don't know, don't try to make up an answer\"\n",
    "\n",
    "    # Replace system prompt\n",
    "    prompt.messages[0] = SystemMessagePromptTemplate.from_template(template)\n",
    "    prompt = ChatPromptTemplate.from_messages(prompt.messages)\n",
    "\n",
    "    if verbose:\n",
    "        print(prompt.messages)\n",
    "        \n",
    "    llm = ChatOpenAI(temperature=temperature)\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    agent_executor = AgentExecutor(agent=agent, tools=tools, \n",
    "                                   memory=ConversationBufferMemory(return_messages=return_messages))\n",
    "    return agent_executor\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
